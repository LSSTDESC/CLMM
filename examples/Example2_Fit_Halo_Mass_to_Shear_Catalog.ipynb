{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Halo Mass from a Shear Catalog\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use `clmm` to estimate a WL halo mass from observations of a galaxy cluster. It uses several functionalities of the support `mock_data` module to produce datasets of increasing complexity. This notebook also demonstrates the bias introduced on the reconstructed mass by a naive fit, when the redshift distribution of the background galaxies is not properly accounted for in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./support')\n",
    "try: import clmm\n",
    "except:\n",
    "    import notebook_install\n",
    "    notebook_install.install_clmm_pipeline(upgrade=False)\n",
    "    import clmm\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from sampler import fitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `clmm`'s core modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import clmm.polaraveraging as pa\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.modeling as modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import a support modules for a specific data sets.\n",
    "`clmm` includes support modules that enable the user to generate mock data in a format compatible with `clmm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mock_data as mock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mock data, we need to define a true cosmology, which is currently done with [`astropy`'s cosmology library](http://docs.astropy.org/en/stable/cosmology/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mock_cosmo = FlatLambdaCDM(H0=70, Om0=0.27, Ob0=0.045)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set some parameters for a mock galaxy cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosmo = mock_cosmo\n",
    "cluster_m = 1.e15\n",
    "cluster_z = 0.3\n",
    "concentration = 4\n",
    "ngals = 2000\n",
    "Delta = 200\n",
    "cluster_ra = 0.0\n",
    "cluster_dec = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `mock_data` support module to generate 3 galaxy catalogs:\n",
    "- `ideal_data`: all background galaxies at the same redshift.\n",
    "- `ideal_data_z`: galaxies distributed according to the Chang et al. (2013) redshift distribution.\n",
    "- `noisy_data_z`: `ideal_data_z` + photoz errors + shape noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_data = mock.generate_galaxy_catalog(cluster_m, cluster_z, concentration, cosmo, ngals, Delta,0.8)\n",
    "ideal_data_z = mock.generate_galaxy_catalog(cluster_m, cluster_z, concentration, cosmo, ngals, Delta,'chang13')\n",
    "noisy_data_z = mock.generate_galaxy_catalog(cluster_m, cluster_z, concentration, cosmo, ngals, Delta,'chang13', \n",
    "                                            shapenoise=0.05, \n",
    "                                            photoz_sigma_unscaled=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The galaxy catalogs are converted to a `clmm.GalaxyCluster` object and may be saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_id = \"CL_ideal\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec,\n",
    "                               cluster_z, ideal_data)\n",
    "gc_object.save('ideal_GC.pkl')\n",
    "\n",
    "cluster_id = \"CL_ideal_z\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec,\n",
    "                               cluster_z, ideal_data_z)\n",
    "gc_object.save('ideal_GC_z.pkl')\n",
    "\n",
    "cluster_id = \"CL_noisy_z\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec,\n",
    "                               cluster_z, noisy_data_z)\n",
    "gc_object.save('noisy_GC_z.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any saved `clmm.GalaxyCluster` object may be read in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl1 = clmm.load_cluster('ideal_GC.pkl') # all background galaxies at the same redshift\n",
    "cl2 = clmm.load_cluster('ideal_GC_z.pkl') # background galaxies distributed according to Chang et al. (2013)\n",
    "cl3 = clmm.load_cluster('noisy_GC_z.pkl') # same as cl2 but with photoz error and shape noise\n",
    "\n",
    "print(\"Cluster info = ID:\", cl2.unique_id, \"; ra:\", cl2.ra, \"; dec:\", cl2.dec, \"; z_l :\", cl2.z)\n",
    "print(\"The number of source galaxies is :\", len(cl2.galcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(cl2.galcat['z'], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing shear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.polaraveraging.compute_shear` calculates the tangential and cross shears for each source galaxy in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta1, g_t1, g_x1 = cl1.compute_shear(geometry=\"flat\")\n",
    "theta2, g_t2, g_x2 = cl2.compute_shear(geometry=\"flat\")\n",
    "theta2, g_t3, g_x3 = cl3.compute_shear(geometry=\"flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radially binning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_edges = pa.make_bins(0.7, 4, 15, method='evenlog10width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.polaraveraging.make_shear_profile` evaluates the average shear of the galaxy catalog in bins of radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile1 = cl1.make_shear_profile(\"radians\", \"Mpc\", bins=bin_edges,cosmo=cosmo)\n",
    "profile2 = cl2.make_shear_profile(\"radians\", \"Mpc\", bins=bin_edges,cosmo=cosmo)\n",
    "profile3 = cl3.make_shear_profile(\"radians\", \"Mpc\", bins=bin_edges,cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `clmm.polaraveraging.make_shear_profile` on a `clmm.GalaxyCluster` object, the object acquires the `clmm.GalaxyCluster.profile` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in cl1.profile.colnames: cl1.profile[n].format = \"%6.3e\"\n",
    "cl1.profile.pprint(max_width=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the radially binned shear for the 3 configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "fsize = 14\n",
    "fig.gca().errorbar(profile1['radius'], profile1['gt'], yerr=profile1['gt_err'], marker='o', label='z_src = 0.8')\n",
    "fig.gca().errorbar(profile2['radius'], profile2['gt'], yerr=profile2['gt_err'], marker='o', \n",
    "                   label='z_src = Chang et al. (2013)')\n",
    "fig.gca().errorbar(profile3['radius'], profile3['gt'], yerr=profile3['gt_err'], marker='o', \n",
    "                   label='z_src = Chang et al. (2013) + photoz err  + shape noise')\n",
    "\n",
    "plt.gca().set_title(r'Binned shear of source galaxies', fontsize=fsize)\n",
    "plt.gca().set_xlabel(r'$r\\;[Mpc]$', fontsize=fsize)\n",
    "plt.gca().set_ylabel(r'$g_t$', fontsize=fsize)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the halo model\n",
    "\n",
    "`clmm.modeling.predict_reduced_tangential_shear` supports various parametric halo profile functions, including `nfw`.\n",
    "Beware that the `clmm.modeling` module works in units of $Mpc/h$, whereas the data is cosmology-independent, with units of $Mpc$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model definition to be used with scipy.optimize.curve_fit\n",
    "def shear_profile_model(r, logm, z_src):\n",
    "    m = 10.**logm\n",
    "    gt_model = clmm.predict_reduced_tangential_shear(r*cosmo.h,\n",
    "                                                     m, concentration,\n",
    "                                                     cluster_z, z_src, cosmo,\n",
    "                                                     delta_mdef=200,\n",
    "                                                     halo_profile_model='nfw')    \n",
    "    return gt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a halo mass - highlighting bias when not accounting for the source redshift distribution in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the best-fit mass using `scipy.optimize.curve_fit`.\n",
    "\n",
    "Here, to build the model we make the WRONG assumption that the average shear in bin $i$ equals the shear at the average redshift in the bin; i.e. we assume that $\\langle g_t\\rangle_i = g_t(\\langle z\\rangle_i)$. This should not impact `cluster 1` as all sources are located at the same redshift. However, this yields a bias in the econstructed mass for `cluster 2` and `cluster 3`, where the sources followed the Chang et al. (2013) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 1:  ideal data\n",
    "popt1,pcov1 = fitters['curve_fit'](lambda r, logm:shear_profile_model(r, logm, profile1['z']), \n",
    "                    profile1['radius'], \n",
    "                    profile1['gt'], \n",
    "                    profile1['gt_err'], bounds=[13.,17.])\n",
    "#popt1,pcov1 = spo.curve_fit(lambda r, logm:shear_profile_model(r, logm, profile1['z']), \n",
    "#                    profile1['radius'], \n",
    "#                    profile1['gt'], \n",
    "#                    sigma=profile1['gt_err'], bounds=[13.,17.])\n",
    "\n",
    "m_est1 = 10.**popt1[0]\n",
    "m_est_err1 =  m_est1 * np.sqrt(pcov1[0][0]) * np.log(10) # convert the error on logm to error on m\n",
    "\n",
    "# Cluster 2:  ideal data with redshift distribution\n",
    "popt2,pcov2 = fitters['curve_fit'](lambda r, logm:shear_profile_model(r, logm, profile2['z']), \n",
    "                    profile2['radius'], \n",
    "                    profile2['gt'], \n",
    "                    profile2['gt_err'], bounds=[13.,17.])\n",
    "\n",
    "m_est2 = 10.**popt2[0]\n",
    "m_est_err2 =  m_est2 * np.sqrt(pcov2[0][0]) * np.log(10) # convert the error on logm to error on m\n",
    "\n",
    "# Cluster 3:  noisy data with redshift distribution\n",
    "popt3,pcov3 = fitters['curve_fit'](lambda r, logm:shear_profile_model(r, logm, profile3['z']), \n",
    "                    profile3['radius'], \n",
    "                    profile3['gt'], \n",
    "                    profile3['gt_err'], bounds=[13.,17.])\n",
    "\n",
    "m_est3 = 10.**popt3[0]\n",
    "m_est_err3 =  m_est3 * np.sqrt(pcov3[0][0]) * np.log(10) # convert the error on logm to error on m\n",
    "\n",
    "\n",
    "\n",
    "print(f'Best fit mass for cluster 1 = {m_est1:.2e} +/- {m_est_err1:.2e} Msun')\n",
    "print(f'Best fit mass for cluster 2 = {m_est2:.2e} +/- {m_est_err2:.2e} Msun')\n",
    "print(f'Best fit mass for cluster 3 = {m_est3:.2e} +/- {m_est_err3:.2e} Msun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the reconstructed mass is biased whenever the sources are not located at a single redshift as this was not accounted for in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the results\n",
    "\n",
    "For visualization purpose, we calculate the reduced tangential shear predicted by the model when using the average redshift of the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr = np.logspace(-0.5, np.log10(5), 100)\n",
    "gt_model1 = clmm.predict_reduced_tangential_shear(rr*cosmo.h,\n",
    "                                                  m_est1, concentration,\n",
    "                                                  cluster_z, np.mean(cl1.galcat['z']), cosmo,\n",
    "                                                  delta_mdef=200,\n",
    "                                                  halo_profile_model='nfw')\n",
    "\n",
    "gt_model2 = clmm.predict_reduced_tangential_shear(rr*cosmo.h,\n",
    "                                                  m_est2, concentration,\n",
    "                                                  cluster_z, np.mean(cl2.galcat['z']), cosmo,\n",
    "                                                  delta_mdef=200,\n",
    "                                                  halo_profile_model='nfw')\n",
    "\n",
    "gt_model3 = clmm.predict_reduced_tangential_shear(rr*cosmo.h,\n",
    "                                                  m_est3, concentration,\n",
    "                                                  cluster_z, np.mean(cl3.galcat['z']), cosmo,\n",
    "                                                  delta_mdef=200,\n",
    "                                                  halo_profile_model='nfw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize that prediction of reduced tangential shear along with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "axes[0].errorbar(profile1['radius'], profile1['gt'],profile1['gt_err'], color='red',\n",
    "                 label='ideal_data, M_input = %.3e Msun' % cluster_m, fmt='.')\n",
    "axes[0].plot(rr, gt_model1,color='red',\n",
    "             label='best fit model 1, M_fit = %.2e +/- %.2e' % (m_est1, m_est_err1))\n",
    "\n",
    "\n",
    "axes[0].errorbar(profile2['radius'], profile2['gt'],profile2['gt_err'], color='green',\n",
    "                  label='ideal_data_z, M_input = %.3e Msun' % cluster_m, fmt='.')\n",
    "axes[0].plot(rr, gt_model2, color='green',\n",
    "               label='best fit model 2, M_fit = %.2e +/- %.2e' % (m_est2, m_est_err2))\n",
    "axes[0].set_title('Ideal data w/wo src redshift distribution',fontsize=fsize)\n",
    "axes[0].semilogx()\n",
    "axes[0].semilogy()\n",
    "axes[0].legend(fontsize=fsize)\n",
    "axes[0].set_xlabel('R [Mpc]', fontsize=fsize)\n",
    "axes[0].set_ylabel('reduced tangential shear', fontsize=fsize)\n",
    "\n",
    "axes[1].errorbar(profile3['radius'], profile3['gt'],profile3['gt_err'], color='red',\n",
    "                label='noisy_data_z, M_input = %.3e Msun' % cluster_m, fmt='.')\n",
    "axes[1].plot(rr, gt_model3,color='red',\n",
    "             label='best fit model 3, M_fit = %.2e +/- %.2e' % (m_est3, m_est_err3))\n",
    "axes[1].set_title('Noisy data with src redshift distribution',fontsize=fsize)\n",
    "axes[1].semilogx()\n",
    "axes[1].semilogy()\n",
    "axes[1].legend(fontsize=fsize)\n",
    "axes[1].set_xlabel('R [Mpc]', fontsize=fsize)\n",
    "axes[1].set_ylabel('reduced tangential shear', fontsize=fsize)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
